#!/usr/bin/env python3
"""
Test du mod√®le YOLOv5 pour le syst√®me de tri DOFbot
V√©rifie le chargement et l'inf√©rence du mod√®le sans ROS
"""

import sys
import os
from pathlib import Path
import unittest

# Racine du projet
PROJECT_ROOT = Path(__file__).parent.parent

# Ajouter YOLOv5 au path Python pour permettre le chargement du mod√®le
YOLOV5_PATH = PROJECT_ROOT / "models" / "yolov5"
sys.path.insert(0, str(YOLOV5_PATH))

try:
    import torch
    import cv2
    import numpy as np
except ImportError as e:
    print(f"‚ùå Erreur import: {e}")
    print("‚ö†Ô∏è  Installez les d√©pendances: pip3 install torch opencv-python")
    sys.exit(1)


class TestYOLOv5Model(unittest.TestCase):
    """Tests pour le mod√®le YOLOv5"""
    
    @classmethod
    def setUpClass(cls):
        """Initialisation avant tous les tests"""
        print("\n" + "="*60)
        print("üß™ TESTS DU MOD√àLE YOLOV5")
        print("="*60 + "\n")
        
        cls.model_path = PROJECT_ROOT / "models" / "best.pt"
        cls.device = None
        cls.model = None
        cls.class_names = ['dangereux', 'menagers', 'recyclables']
    
    def test_01_model_file_exists(self):
        """Test 1: V√©rifier que le fichier mod√®le existe"""
        print("üìù Test 1: Existence du fichier mod√®le...")
        self.assertTrue(
            self.model_path.exists(),
            f"‚ùå Mod√®le introuvable: {self.model_path}"
        )
        
        # V√©rifier la taille
        size_mb = self.model_path.stat().st_size / (1024 * 1024)
        print(f"   ‚úÖ Mod√®le trouv√©: {size_mb:.1f} MB")
        self.assertGreater(size_mb, 30, "‚ùå Fichier mod√®le trop petit")
        self.assertLess(size_mb, 50, "‚ùå Fichier mod√®le trop gros")
    
    def test_02_device_selection(self):
        """Test 2: S√©lection du device (CUDA ou CPU)"""
        print("üìù Test 2: S√©lection du device...")
        
        # S√©lection automatique device
        if torch.cuda.is_available():
            TestYOLOv5Model.device = torch.device('cuda')
            print(f"   üöÄ GPU disponible: {torch.cuda.get_device_name(0)}")
        else:
            TestYOLOv5Model.device = torch.device('cpu')
            print("   ‚ö†Ô∏è  GPU non disponible, utilisation CPU")
        
        print(f"   ‚úÖ Device s√©lectionn√©: {TestYOLOv5Model.device}")
    
    def test_03_model_loading(self):
        """Test 3: Chargement du mod√®le"""
        print("üìù Test 3: Chargement du mod√®le...")
        
        # Charger directement avec torch.load (weights_only=False pour YOLOv5)
        try:
            checkpoint = torch.load(
                str(self.model_path),
                map_location=TestYOLOv5Model.device,
                weights_only=False
            )
            TestYOLOv5Model.model = checkpoint['model'].float().eval()
        except:
            # Fallback: charger le mod√®le entier
            TestYOLOv5Model.model = torch.load(
                str(self.model_path),
                map_location=TestYOLOv5Model.device,
                weights_only=False
            )
            TestYOLOv5Model.model.eval()
        
        self.assertIsNotNone(TestYOLOv5Model.model, "‚ùå √âchec chargement mod√®le")
        print("   ‚úÖ Mod√®le charg√© avec succ√®s")
        
        # V√©rifier les noms de classes (si disponibles)
        try:
            model_names = (
                TestYOLOv5Model.model.module.names
                if hasattr(TestYOLOv5Model.model, 'module')
                else TestYOLOv5Model.model.names
            )
            print(f"   üìä Classes: {model_names}")
            self.assertEqual(len(model_names), 3, "‚ùå Nombre de classes incorrect")
        except:
            print(f"   üìä Classes: {self.class_names} (depuis config)")
    
    def test_04_inference_random_image(self):
        """Test 4: Inf√©rence sur image al√©atoire"""
        print("üìù Test 4: Inf√©rence sur image al√©atoire...")
        
        # Cr√©er une image al√©atoire
        test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        
        # Preprocessing
        img = cv2.resize(test_image, (640, 640))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = np.transpose(img, (2, 0, 1))
        img = torch.from_numpy(img).to(TestYOLOv5Model.device)
        img = img.float() / 255.0
        
        if img.ndimension() == 3:
            img = img.unsqueeze(0)
        
        # Inf√©rence
        import time
        start = time.time()
        
        with torch.no_grad():
            pred = TestYOLOv5Model.model(img)[0]
        
        inference_time = (time.time() - start) * 1000
        
        print(f"   ‚úÖ Inf√©rence r√©ussie: {inference_time:.1f} ms")
        self.assertIsNotNone(pred, "‚ùå Pr√©diction None")
        self.assertLess(inference_time, 1000, "‚ùå Inf√©rence trop lente (>1000ms)")
        
        # V√©rifier output shape
        print(f"   üìä Output shape: {pred.shape}")
        print(f"   ‚úÖ Inf√©rence valid√©e (NMS √† faire sur Jetson)")
    
    def test_05_inference_batch(self):
        """Test 5: Inf√©rence par batch"""
        print("üìù Test 5: Inf√©rence par batch (4 images)...")
        
        # Cr√©er 4 images al√©atoires
        batch_size = 4
        images = [
            np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
            for _ in range(batch_size)
        ]
        
        # Preprocessing
        batch = []
        for image in images:
            img = cv2.resize(image, (640, 640))
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = np.transpose(img, (2, 0, 1))
            img = torch.from_numpy(img).to(TestYOLOv5Model.device)
            img = img.float() / 255.0
            batch.append(img)
        
        batch_tensor = torch.stack(batch)
        
        # Inf√©rence
        import time
        start = time.time()
        
        with torch.no_grad():
            pred = TestYOLOv5Model.model(batch_tensor)[0]
        
        batch_time = (time.time() - start) * 1000
        time_per_image = batch_time / batch_size
        
        print(f"   ‚úÖ Batch inf√©rence: {batch_time:.1f} ms total")
        print(f"   ‚ö° Temps/image: {time_per_image:.1f} ms")
        print(f"   üöÄ FPS: {1000/time_per_image:.1f}")
        
        self.assertIsNotNone(pred, "‚ùå Pr√©diction batch None")
    
    def test_06_confidence_thresholds(self):
        """Test 6: Test des seuils de confiance"""
        print("üìù Test 6: Test seuils de confiance...")
        
        # Image test
        test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        
        # Preprocessing
        img = cv2.resize(test_image, (640, 640))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = np.transpose(img, (2, 0, 1))
        img = torch.from_numpy(img).to(TestYOLOv5Model.device)
        img = img.float() / 255.0
        img = img.unsqueeze(0)
        
        # Tester diff√©rents seuils
        thresholds = [0.3, 0.5, 0.6, 0.8]
        
        with torch.no_grad():
            pred = TestYOLOv5Model.model(img)[0]
        
        for thresh in thresholds:
            # Compter d√©tections avec seuil (simplifi√© sans NMS complet)
            print(f"   üìä Seuil {thresh:.1f}: test inf√©rence OK")
        
        print("   ‚úÖ Test seuils OK (NMS complet sur Jetson)")


class TestModelPerformance(unittest.TestCase):
    """Tests de performance du mod√®le"""
    
    def test_inference_speed(self):
        """Test de la vitesse d'inf√©rence"""
        print("\nüìù Test Performance: Vitesse d'inf√©rence...")
        
        # Charger le mod√®le
        model_path = PROJECT_ROOT / "models" / "best.pt"
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        try:
            checkpoint = torch.load(
                str(model_path),
                map_location=device,
                weights_only=False
            )
            model = checkpoint['model'].float().eval()
        except:
            model = torch.load(
                str(model_path),
                map_location=device,
                weights_only=False
            )
            model.eval()
        
        # Cr√©er image test
        test_image = np.random.randint(0, 255, (480, 640, 3), dtype=np.uint8)
        img = cv2.resize(test_image, (640, 640))
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = np.transpose(img, (2, 0, 1))
        img = torch.from_numpy(img).to(device).float() / 255.0
        img = img.unsqueeze(0)
        
        # Warm-up
        with torch.no_grad():
            model(img)
        
        # Mesurer sur 10 inf√©rences
        import time
        times = []
        num_runs = 10
        
        for _ in range(num_runs):
            start = time.time()
            with torch.no_grad():
                pred = model(img)[0]
            times.append((time.time() - start) * 1000)
        
        avg_time = np.mean(times)
        std_time = np.std(times)
        
        print(f"   üìä Temps moyen: {avg_time:.1f} ¬± {std_time:.1f} ms")
        print(f"   üöÄ FPS moyen: {1000/avg_time:.1f}")
        
        # Sur Jetson Nano GPU, on attend <100ms
        # Sur CPU, on attend <500ms
        if device.type == 'cuda':
            self.assertLess(avg_time, 100, "‚ùå Inf√©rence GPU trop lente")
        else:
            self.assertLess(avg_time, 500, "‚ùå Inf√©rence CPU trop lente")


def run_tests():
    """Lancer tous les tests"""
    # Cr√©er une suite de tests
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # Ajouter les tests
    suite.addTests(loader.loadTestsFromTestCase(TestYOLOv5Model))
    suite.addTests(loader.loadTestsFromTestCase(TestModelPerformance))
    
    # Ex√©cuter
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # R√©sum√©
    print("\n" + "="*60)
    print("üìä R√âSUM√â DES TESTS")
    print("="*60)
    print(f"‚úÖ Tests r√©ussis: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"‚ùå Tests √©chou√©s: {len(result.failures)}")
    print(f"‚ö†Ô∏è  Erreurs: {len(result.errors)}")
    print("="*60 + "\n")
    
    return result.wasSuccessful()


if __name__ == "__main__":
    success = run_tests()
    sys.exit(0 if success else 1)
