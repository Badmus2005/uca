# ğŸ¤– GUIDE DÃ‰PLOIEMENT MODÃˆLE SUR ROBOT JETSON NANO

**Date :** 12 octobre 2025  
**Objectif :** TransfÃ©rer et intÃ©grer le modÃ¨le YOLOv5 entraÃ®nÃ© vers l'architecture ROS du DOFBot

---

## ğŸ“‹ TABLE DES MATIÃˆRES

1. [Architecture actuelle](#architecture-actuelle)
2. [Structure du dossier models/](#structure-du-dossier-models)
3. [Fichiers Ã  transfÃ©rer](#fichiers-Ã -transfÃ©rer)
4. [ProcÃ©dure de dÃ©ploiement](#procÃ©dure-de-dÃ©ploiement)
5. [Modification du vision_node.py](#modification-du-vision_nodepy)
6. [Optimisation pour Jetson Nano](#optimisation-pour-jetson-nano)
7. [Tests sur robot](#tests-sur-robot)

---

## ğŸ—ï¸ ARCHITECTURE ACTUELLE

### Sur votre PC local (Windows)
```
D:\TRC2025\docTel\TRC_Doc\TRC\dofbot_tri_complete\
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ trained_models/
â”‚   â”‚   â””â”€â”€ garbage_classifier_v1/
â”‚   â”‚       â”œâ”€â”€ weights/
â”‚   â”‚       â”‚   â”œâ”€â”€ best.pt          â† â­ MODÃˆLE PRINCIPAL (40.6 MB)
â”‚   â”‚       â”‚   â””â”€â”€ last.pt          â† Dernier checkpoint
â”‚   â”‚       â”œâ”€â”€ hyp.yaml             â† HyperparamÃ¨tres
â”‚   â”‚       â”œâ”€â”€ opt.yaml             â† Options entraÃ®nement
â”‚   â”‚       â””â”€â”€ results.png          â† Graphiques performance
â”‚   â””â”€â”€ yolov5/                       â† Framework YOLOv5 complet
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset.yaml                  â† Configuration classes
â”‚
â””â”€â”€ config/
    â””â”€â”€ hyp.yaml                      â† HyperparamÃ¨tres training
```

### Sur le robot Jetson Nano (Ubuntu + ROS)
```
~/catkin_ws/src/dofbot_tri/
â”œâ”€â”€ CMakeLists.txt
â”œâ”€â”€ package.xml
â”œâ”€â”€ srv/
â”‚   â””â”€â”€ Classify.srv
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ vision_node.py               â† â­ Ã€ MODIFIER (utilise le modÃ¨le)
â”‚   â”œâ”€â”€ i2c_controller_node.py
â”‚   â””â”€â”€ test_calibration.py
â”œâ”€â”€ launch/
â”‚   â””â”€â”€ tri.launch
â”œâ”€â”€ models/                           â† â­ Ã€ COMPLÃ‰TER
â”‚   â””â”€â”€ (...)
â””â”€â”€ config/
    â””â”€â”€ arm_positions.yaml
```

---

## ğŸ“‚ STRUCTURE DU DOSSIER `models/` (SUR ROBOT)

Voici **exactement** ce que doit contenir `~/catkin_ws/src/dofbot_tri/models/` :

### âœ… Option 1 : Structure minimale (RECOMMANDÃ‰E pour Jetson Nano)

```
~/catkin_ws/src/dofbot_tri/models/
â”œâ”€â”€ best.pt                           â† â­ ModÃ¨le principal (40.6 MB)
â”œâ”€â”€ dataset.yaml                      â† Configuration classes
â””â”€â”€ yolov5/                           â† Framework YOLOv5 (seulement fichiers essentiels)
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ common.py                 â† Architectures rÃ©seau
    â”‚   â”œâ”€â”€ yolo.py                   â† DÃ©tecteur YOLO
    â”‚   â””â”€â”€ experimental.py           â† Fonctions expÃ©rimentales
    â”œâ”€â”€ utils/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ general.py                â† Fonctions utilitaires
    â”‚   â”œâ”€â”€ torch_utils.py            â† Utilitaires PyTorch
    â”‚   â”œâ”€â”€ augmentations.py          â† Augmentations
    â”‚   â”œâ”€â”€ dataloaders.py            â† Chargeurs donnÃ©es
    â”‚   â””â”€â”€ plots.py                  â† Visualisation (optionnel)
    â”œâ”€â”€ __init__.py
    â””â”€â”€ requirements.txt              â† DÃ©pendances Python
```

**Taille totale :** ~45 MB (modÃ¨le + YOLOv5 essentiel)

---

### âœ… Option 2 : Structure complÃ¨te (avec backup et versions)

```
~/catkin_ws/src/dofbot_tri/models/
â”œâ”€â”€ current/                          â† â­ ModÃ¨le actuellement utilisÃ©
â”‚   â”œâ”€â”€ best.pt                       â† Lien symbolique â†’ ../v1/best.pt
â”‚   â””â”€â”€ dataset.yaml                  â† Configuration classes
â”‚
â”œâ”€â”€ v1/                               â† Version 1 (85.2% accuracy)
â”‚   â”œâ”€â”€ best.pt                       â† ModÃ¨le v1
â”‚   â”œâ”€â”€ hyp.yaml                      â† HyperparamÃ¨tres
â”‚   â”œâ”€â”€ opt.yaml                      â† Options
â”‚   â””â”€â”€ results.png                   â† Performance graphs
â”‚
â”œâ”€â”€ v2/                               â† Future version 2 (si rÃ©entraÃ®nement)
â”‚   â””â”€â”€ best.pt                       â† ModÃ¨le v2 (Ã  venir)
â”‚
â”œâ”€â”€ tensorrt/                         â† ModÃ¨les optimisÃ©s TensorRT (futur)
â”‚   â”œâ”€â”€ best.engine                   â† TensorRT FP16
â”‚   â””â”€â”€ best_int8.engine              â† TensorRT INT8
â”‚
â”œâ”€â”€ yolov5/                           â† Framework YOLOv5
â”‚   â””â”€â”€ (...)
â”‚
â””â”€â”€ README.md                         â† Documentation versions
```

**Taille totale :** ~150 MB (avec backups)

---

## ğŸ“¦ FICHIERS Ã€ TRANSFÃ‰RER

### ğŸ”´ FICHIERS OBLIGATOIRES (Minimum vital)

| Fichier Local | Destination Robot | Taille | PrioritÃ© |
|---------------|-------------------|--------|----------|
| `models/trained_models/garbage_classifier_v1/weights/best.pt` | `~/catkin_ws/src/dofbot_tri/models/best.pt` | 40.6 MB | â­ CRITIQUE |
| `data/dataset.yaml` | `~/catkin_ws/src/dofbot_tri/models/dataset.yaml` | 1 KB | â­ CRITIQUE |
| `models/yolov5/models/` (dossier complet) | `~/catkin_ws/src/dofbot_tri/models/yolov5/models/` | ~500 KB | â­ CRITIQUE |
| `models/yolov5/utils/` (dossier complet) | `~/catkin_ws/src/dofbot_tri/models/yolov5/utils/` | ~1 MB | â­ CRITIQUE |

### ğŸŸ¡ FICHIERS RECOMMANDÃ‰S (Pour debug et monitoring)

| Fichier Local | Destination Robot | Taille | Usage |
|---------------|-------------------|--------|-------|
| `models/trained_models/garbage_classifier_v1/hyp.yaml` | `~/catkin_ws/src/dofbot_tri/models/v1/hyp.yaml` | 1 KB | Documentation |
| `models/trained_models/garbage_classifier_v1/opt.yaml` | `~/catkin_ws/src/dofbot_tri/models/v1/opt.yaml` | 1 KB | Configuration |
| `models/trained_models/garbage_classifier_v1/results.png` | `~/catkin_ws/src/dofbot_tri/models/v1/results.png` | ~100 KB | Performance |

### ğŸŸ¢ FICHIERS OPTIONNELS (Pas nÃ©cessaires sur robot)

| Fichier | Raison |
|---------|--------|
| `last.pt` | Backup inutile (best.pt suffit) |
| `train_batch*.jpg` | Images debug training |
| `val_batch*.jpg` | Images debug validation |
| `confusion_matrix.png` | Analyse locale uniquement |
| `events.out.tfevents.*` | Logs TensorBoard (PC uniquement) |

---

## ğŸš€ PROCÃ‰DURE DE DÃ‰PLOIEMENT

### Ã‰tape 1 : PrÃ©parer les fichiers sur PC

#### 1.1 CrÃ©er un dossier de transfert
```powershell
# Sur votre PC Windows
cd D:\TRC2025\docTel\TRC_Doc\TRC\dofbot_tri_complete
mkdir deploy_to_robot
```

#### 1.2 Copier les fichiers essentiels
```powershell
# ModÃ¨le principal
Copy-Item models\trained_models\garbage_classifier_v1\weights\best.pt deploy_to_robot\

# Configuration dataset
Copy-Item data\dataset.yaml deploy_to_robot\

# Framework YOLOv5 (seulement dossiers essentiels)
Copy-Item -Recurse models\yolov5\models deploy_to_robot\yolov5_models
Copy-Item -Recurse models\yolov5\utils deploy_to_robot\yolov5_utils

# Fichiers Python racine YOLOv5
Copy-Item models\yolov5\__init__.py deploy_to_robot\yolov5_init.py
```

#### 1.3 CrÃ©er une archive (optionnel mais recommandÃ©)
```powershell
# Compresser pour transfert plus rapide
Compress-Archive -Path deploy_to_robot\* -DestinationPath deploy_to_robot.zip
```

---

### Ã‰tape 2 : TransfÃ©rer vers le Jetson Nano

#### Option A : Via SCP (SSH File Transfer)
```bash
# Sur votre PC (PowerShell)
# Remplacez <JETSON_IP> par l'IP de votre Jetson Nano
scp -r deploy_to_robot/* jetson@<JETSON_IP>:~/transfer/

# Exemple : scp -r deploy_to_robot/* jetson@192.168.1.100:~/transfer/
```

#### Option B : Via clÃ© USB
```bash
1. Copier deploy_to_robot/ sur clÃ© USB
2. InsÃ©rer clÃ© USB dans Jetson Nano
3. Monter et copier :
   sudo mount /dev/sda1 /mnt/usb
   cp -r /mnt/usb/deploy_to_robot/* ~/transfer/
```

#### Option C : Via rÃ©seau partagÃ© (si mÃªme rÃ©seau WiFi)
```bash
# Sur PC : Partager le dossier deploy_to_robot via Windows
# Sur Jetson : AccÃ©der au partage rÃ©seau et copier
```

---

### Ã‰tape 3 : Installer sur le robot

```bash
# SSH vers le Jetson Nano
ssh jetson@<JETSON_IP>

# Naviguer vers le workspace ROS
cd ~/catkin_ws/src/dofbot_tri/

# CrÃ©er la structure models/
mkdir -p models/yolov5/models
mkdir -p models/yolov5/utils
mkdir -p models/v1

# Copier les fichiers
cp ~/transfer/best.pt models/best.pt
cp ~/transfer/dataset.yaml models/dataset.yaml
cp -r ~/transfer/yolov5_models/* models/yolov5/models/
cp -r ~/transfer/yolov5_utils/* models/yolov5/utils/
cp ~/transfer/yolov5_init.py models/yolov5/__init__.py

# VÃ©rifier la structure
tree models/ -L 2
```

**RÃ©sultat attendu :**
```
models/
â”œâ”€â”€ best.pt                    â† 40.6 MB
â”œâ”€â”€ dataset.yaml              â† 1 KB
â””â”€â”€ yolov5/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ models/               â† ~500 KB
    â”‚   â”œâ”€â”€ common.py
    â”‚   â”œâ”€â”€ yolo.py
    â”‚   â””â”€â”€ ...
    â””â”€â”€ utils/                â† ~1 MB
        â”œâ”€â”€ general.py
        â”œâ”€â”€ torch_utils.py
        â””â”€â”€ ...
```

---

## ğŸ”§ MODIFICATION DU `vision_node.py`

Votre script ROS doit charger et utiliser le modÃ¨le. Voici comment :

### Code actuel (exemple hypothÃ©tique)
```python
#!/usr/bin/env python3
import rospy
from sensor_msgs.msg import Image
from cv_bridge import CvBridge

class VisionNode:
    def __init__(self):
        rospy.init_node('vision_node')
        # TODO: Charger le modÃ¨le YOLOv5
        pass
    
    def classify_image(self, image):
        # TODO: Utiliser le modÃ¨le pour classifier
        pass
```

### Code modifiÃ© (avec YOLOv5)
```python
#!/usr/bin/env python3
import rospy
import torch
import sys
import os
from pathlib import Path
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import cv2
import numpy as np

# Ajouter le chemin YOLOv5 au PYTHONPATH
FILE = Path(__file__).resolve()
ROOT = FILE.parents[1] / 'models' / 'yolov5'  # ~/catkin_ws/src/dofbot_tri/models/yolov5
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))

from models.common import DetectMultiBackend
from utils.general import check_img_size, non_max_suppression, scale_boxes
from utils.torch_utils import select_device
from utils.augmentations import letterbox

class VisionNode:
    def __init__(self):
        rospy.init_node('vision_node')
        
        # ParamÃ¨tres
        self.model_path = rospy.get_param('~model_path', 
            str(FILE.parents[1] / 'models' / 'best.pt'))
        self.conf_threshold = rospy.get_param('~conf_threshold', 0.5)
        self.img_size = rospy.get_param('~img_size', 640)
        
        # Initialiser le modÃ¨le
        rospy.loginfo("Chargement du modÃ¨le YOLOv5...")
        self.device = select_device('cuda:0' if torch.cuda.is_available() else 'cpu')
        self.model = DetectMultiBackend(self.model_path, device=self.device, dnn=False)
        self.stride = self.model.stride
        self.img_size = check_img_size(self.img_size, s=self.stride)
        self.names = self.model.names  # ['dangereux', 'menagers', 'recyclables']
        
        rospy.loginfo(f"ModÃ¨le chargÃ© sur {self.device}")
        rospy.loginfo(f"Classes: {self.names}")
        
        # Bridge ROS-OpenCV
        self.bridge = CvBridge()
        
        # Subscriber pour les images
        self.image_sub = rospy.Subscriber('/camera/image_raw', Image, self.image_callback)
        
        # Service ROS pour classification
        from dofbot_tri.srv import Classify, ClassifyResponse
        self.classify_service = rospy.Service('classify_waste', Classify, self.classify_service_handler)
        
        rospy.loginfo("Vision Node prÃªt !")
    
    def preprocess_image(self, img):
        """PrÃ©traiter l'image pour YOLOv5"""
        img = letterbox(img, self.img_size, stride=self.stride, auto=True)[0]
        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
        img = np.ascontiguousarray(img)
        img = torch.from_numpy(img).to(self.device)
        img = img.float() / 255.0  # 0 - 255 to 0.0 - 1.0
        if len(img.shape) == 3:
            img = img[None]  # expand for batch dim
        return img
    
    def classify_image(self, cv_image):
        """
        Classifier une image avec YOLOv5
        
        Returns:
            class_name (str): 'dangereux', 'menagers', ou 'recyclables'
            confidence (float): Confiance de la prÃ©diction (0-1)
        """
        # PrÃ©traitement
        img = self.preprocess_image(cv_image)
        
        # InfÃ©rence
        with torch.no_grad():
            pred = self.model(img, augment=False, visualize=False)
        
        # Post-traitement (NMS)
        pred = non_max_suppression(pred, self.conf_threshold, 0.45, None, False, max_det=10)
        
        # Extraire la meilleure prÃ©diction
        if len(pred[0]) > 0:
            # Prendre la dÃ©tection avec la plus haute confiance
            best_det = pred[0][0]  # [x1, y1, x2, y2, conf, class]
            class_id = int(best_det[5])
            confidence = float(best_det[4])
            class_name = self.names[class_id]
            
            rospy.loginfo(f"DÃ©tection: {class_name} (confiance: {confidence:.2f})")
            return class_name, confidence
        else:
            rospy.logwarn("Aucune dÃ©tection !")
            return None, 0.0
    
    def image_callback(self, msg):
        """Callback pour les images de la camÃ©ra"""
        try:
            cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
            class_name, confidence = self.classify_image(cv_image)
            
            if class_name and confidence > self.conf_threshold:
                rospy.loginfo(f"Cube dÃ©tectÃ©: {class_name}")
                # TODO: Publier sur un topic ou appeler le service du bras
                
        except Exception as e:
            rospy.logerr(f"Erreur traitement image: {e}")
    
    def classify_service_handler(self, req):
        """Handler pour le service ROS Classify"""
        from dofbot_tri.srv import ClassifyResponse
        
        try:
            cv_image = self.bridge.imgmsg_to_cv2(req.image, "bgr8")
            class_name, confidence = self.classify_image(cv_image)
            
            return ClassifyResponse(
                waste_type=class_name if class_name else "unknown",
                confidence=confidence
            )
        except Exception as e:
            rospy.logerr(f"Erreur service classification: {e}")
            return ClassifyResponse(waste_type="error", confidence=0.0)

if __name__ == '__main__':
    try:
        node = VisionNode()
        rospy.spin()
    except rospy.ROSInterruptException:
        pass
```

### Fichier `Classify.srv`
```
# Request
sensor_msgs/Image image

---
# Response
string waste_type      # 'dangereux', 'menagers', 'recyclables', ou 'unknown'
float32 confidence     # 0.0 Ã  1.0
```

---

## âš¡ OPTIMISATION POUR JETSON NANO

Le Jetson Nano a des ressources limitÃ©es. Voici comment optimiser :

### 1. Utiliser TensorRT (RECOMMANDÃ‰)

```bash
# Sur le Jetson Nano
cd ~/catkin_ws/src/dofbot_tri/models/

# Exporter vers TensorRT FP16 (2-3Ã— plus rapide)
python3 -c "
from yolov5.models.common import DetectMultiBackend
import torch

model = DetectMultiBackend('best.pt', device='cuda:0', dnn=False)
dummy_input = torch.randn(1, 3, 640, 640).to('cuda:0')

# Export TorchScript
ts = torch.jit.trace(model.model, dummy_input)
ts.save('best_traced.torchscript')

print('ModÃ¨le TorchScript exportÃ©: best_traced.torchscript')
"

# Utiliser dans vision_node.py:
# self.model = DetectMultiBackend('best_traced.torchscript', device=self.device)
```

**Gain :** 300ms â†’ 100-150ms par infÃ©rence

### 2. RÃ©duire la taille d'image

```python
# Dans vision_node.py
self.img_size = 416  # Au lieu de 640
```

**Gain :** 300ms â†’ 150ms (mais -2% accuracy)

### 3. Utiliser CUDA si disponible

```python
self.device = select_device('cuda:0')  # Force GPU Jetson
```

### 4. Optimiser OpenCV

```bash
# Installer OpenCV avec CUDA support (si pas dÃ©jÃ  fait)
sudo apt-get install python3-opencv
```

---

## ğŸ§ª TESTS SUR ROBOT

### Test 1 : VÃ©rifier le chargement du modÃ¨le

```bash
# SSH vers Jetson
ssh jetson@<JETSON_IP>

# Naviguer vers le workspace
cd ~/catkin_ws/src/dofbot_tri/models/

# Test Python direct
python3 << EOF
import torch
from pathlib import Path

model_path = 'best.pt'
print(f"Chargement de {model_path}...")

model = torch.hub.load('yolov5', 'custom', path=model_path, source='local')
print(f"âœ… ModÃ¨le chargÃ© avec succÃ¨s!")
print(f"Classes: {model.names}")
EOF
```

**Sortie attendue :**
```
Chargement de best.pt...
âœ… ModÃ¨le chargÃ© avec succÃ¨s!
Classes: ['dangereux', 'menagers', 'recyclables']
```

### Test 2 : Test d'infÃ©rence avec une image

```bash
# Copier une image de test
scp data/prepared/val/images/dangereux_* jetson@<JETSON_IP>:~/test_image.jpg

# Sur Jetson
cd ~/catkin_ws/src/dofbot_tri/models/
python3 << EOF
import torch
from PIL import Image

model = torch.hub.load('yolov5', 'custom', path='best.pt', source='local')
img = Image.open('~/test_image.jpg')

results = model(img)
results.print()
results.show()  # Si X11 forwarding activÃ©
EOF
```

### Test 3 : Lancer le node ROS

```bash
# Source le workspace
cd ~/catkin_ws
source devel/setup.bash

# Lancer le node vision
rosrun dofbot_tri vision_node.py
```

**Logs attendus :**
```
[ INFO] [1697123456.789]: Chargement du modÃ¨le YOLOv5...
[ INFO] [1697123458.123]: ModÃ¨le chargÃ© sur cuda:0
[ INFO] [1697123458.124]: Classes: ['dangereux', 'menagers', 'recyclables']
[ INFO] [1697123458.125]: Vision Node prÃªt !
```

### Test 4 : Test du service de classification

```bash
# Terminal 1 : Lancer le node
rosrun dofbot_tri vision_node.py

# Terminal 2 : Appeler le service
rosservice call /classify_waste "image: {data: []}"  # Avec vraie image
```

---

## ğŸ“Š STRUCTURE FINALE COMPLÃˆTE

### Sur le robot aprÃ¨s dÃ©ploiement

```
~/catkin_ws/src/dofbot_tri/
â”œâ”€â”€ CMakeLists.txt
â”œâ”€â”€ package.xml
â”‚
â”œâ”€â”€ srv/
â”‚   â””â”€â”€ Classify.srv                  â† Service classification
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ vision_node.py               â† â­ MODIFIÃ‰ (charge best.pt)
â”‚   â”œâ”€â”€ i2c_controller_node.py       â† ContrÃ´le bras
â”‚   â”œâ”€â”€ test_calibration.py
â”‚   â””â”€â”€ test_model.py                â† â­ NOUVEAU (test modÃ¨le standalone)
â”‚
â”œâ”€â”€ launch/
â”‚   â””â”€â”€ tri.launch                    â† â­ Ã€ MODIFIER (lance vision_node)
â”‚
â”œâ”€â”€ models/                           â† â­ NOUVEAU (dossier complet)
â”‚   â”œâ”€â”€ best.pt                       â† ModÃ¨le principal (40.6 MB)
â”‚   â”œâ”€â”€ dataset.yaml                  â† Config classes
â”‚   â”œâ”€â”€ best_traced.torchscript       â† ModÃ¨le optimisÃ© TensorRT (optionnel)
â”‚   â”‚
â”‚   â”œâ”€â”€ yolov5/                       â† Framework YOLOv5
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ common.py
â”‚   â”‚   â”‚   â”œâ”€â”€ yolo.py
â”‚   â”‚   â”‚   â””â”€â”€ experimental.py
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ general.py
â”‚   â”‚       â”œâ”€â”€ torch_utils.py
â”‚   â”‚       â”œâ”€â”€ augmentations.py
â”‚   â”‚       â””â”€â”€ dataloaders.py
â”‚   â”‚
â”‚   â””â”€â”€ v1/                           â† Backup version 1
â”‚       â”œâ”€â”€ hyp.yaml
â”‚       â”œâ”€â”€ opt.yaml
â”‚       â””â”€â”€ results.png
â”‚
â””â”€â”€ config/
    â”œâ”€â”€ arm_positions.yaml            â† Positions bras
    â””â”€â”€ vision_params.yaml            â† â­ NOUVEAU (params vision)
```

---

## ğŸ“ CHECKLIST DÃ‰PLOIEMENT

### Avant transfert (sur PC)
- [ ] VÃ©rifier que `best.pt` existe et fonctionne (85.2%)
- [ ] Copier fichiers dans `deploy_to_robot/`
- [ ] VÃ©rifier taille totale (~42 MB)
- [ ] CrÃ©er archive ZIP (optionnel)

### Transfert
- [ ] TransfÃ©rer via SCP/USB vers Jetson
- [ ] VÃ©rifier intÃ©gritÃ© fichiers (tailles)
- [ ] VÃ©rifier permissions (chmod +x si nÃ©cessaire)

### Installation sur robot
- [ ] CrÃ©er structure `~/catkin_ws/src/dofbot_tri/models/`
- [ ] Copier `best.pt` et `dataset.yaml`
- [ ] Copier framework YOLOv5
- [ ] VÃ©rifier avec `tree models/`

### Modification code ROS
- [ ] Mettre Ã  jour `vision_node.py` avec code YOLOv5
- [ ] CrÃ©er `Classify.srv` si pas existant
- [ ] Mettre Ã  jour `CMakeLists.txt` (ajouter srv)
- [ ] Mettre Ã  jour `tri.launch`

### Tests
- [ ] Test chargement modÃ¨le Python standalone
- [ ] Test infÃ©rence sur image test
- [ ] Test lancement node ROS
- [ ] Test service de classification
- [ ] Test avec camÃ©ra rÃ©elle

### Optimisation (optionnel)
- [ ] Export TorchScript/TensorRT
- [ ] Benchmark vitesse (cible <150ms)
- [ ] Ajuster paramÃ¨tres (img_size, conf_threshold)

---

## ğŸ¯ RÃ‰SUMÃ‰ : FICHIERS ESSENTIELS Ã€ COPIER

| # | Fichier Source (PC) | Destination (Robot) | Taille |
|---|---------------------|---------------------|--------|
| 1 | `models/trained_models/garbage_classifier_v1/weights/best.pt` | `~/catkin_ws/src/dofbot_tri/models/best.pt` | 40.6 MB |
| 2 | `data/dataset.yaml` | `~/catkin_ws/src/dofbot_tri/models/dataset.yaml` | 1 KB |
| 3 | `models/yolov5/models/` (complet) | `~/catkin_ws/src/dofbot_tri/models/yolov5/models/` | 500 KB |
| 4 | `models/yolov5/utils/` (complet) | `~/catkin_ws/src/dofbot_tri/models/yolov5/utils/` | 1 MB |
| 5 | `models/yolov5/__init__.py` | `~/catkin_ws/src/dofbot_tri/models/yolov5/__init__.py` | 1 KB |

**TOTAL :** ~42 MB

---

## ğŸš¨ PROBLÃˆMES COURANTS

### Erreur : "No module named 'models'"
```bash
# Solution : Ajouter yolov5 au PYTHONPATH
export PYTHONPATH=$PYTHONPATH:~/catkin_ws/src/dofbot_tri/models/yolov5
```

### Erreur : "CUDA out of memory"
```python
# Solution : RÃ©duire batch size ou img_size
self.img_size = 416  # Au lieu de 640
```

### Erreur : "Cannot load model weights"
```bash
# Solution : VÃ©rifier intÃ©gritÃ© fichier
ls -lh ~/catkin_ws/src/dofbot_tri/models/best.pt
# Doit faire ~40.6 MB
```

### Performance lente (>500ms par image)
```python
# Solution 1 : VÃ©rifier que CUDA est utilisÃ©
print(f"Device: {self.device}")  # Doit afficher 'cuda:0'

# Solution 2 : Exporter en TorchScript
# Voir section "Optimisation pour Jetson Nano"
```

---

## ğŸ“š RESSOURCES

- **YOLOv5 Documentation :** https://docs.ultralytics.com/
- **ROS Services :** http://wiki.ros.org/Services
- **Jetson Nano Setup :** https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit
- **TensorRT Optimization :** https://github.com/ultralytics/yolov5/issues/251

---

## ğŸ† PROCHAINES Ã‰TAPES

AprÃ¨s dÃ©ploiement rÃ©ussi :

1. âœ… ModÃ¨le dÃ©ployÃ© sur robot
2. â³ Tests avec cubes physiques + camÃ©ra
3. â³ IntÃ©gration complÃ¨te (vision + bras + tri)
4. â³ Optimisation vitesse (TensorRT)
5. â³ Tests competition complÃ¨te

**Objectif :** SystÃ¨me fonctionnel pour TRC2025 ! ğŸš€
